services:
  ollama:
    image: ollama/ollama
    hostname: ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama
  ollama-pull-model:
    image: alpine/curl
    hostname: ollama-pull-model
    container_name: ollama-pull-model
    depends_on:
      - ollama
    command: ["http://ollama:11434/api/pull","-d","{\"model\":\"llama3.2\",\"insecure\":true,\"stream\":false}"]
  ollama-load-model:
    image: alpine/curl
    hostname: ollama-load-model
    container_name: ollama-load-model
    depends_on:
      ollama-pull-model:
        condition: service_completed_successfully
    command: ["http://ollama:11434/api/generate","-d","{\"model\":\"llama3.2\",\"keep_alive\":\"30m\",\"stream\":false}"]
  wait-for-ollama:
    image: backplane/true
    hostname: wait-for-ollama
    container_name: wait-for-ollama
    depends_on:
      ollama-load-model:
        condition: service_completed_successfully